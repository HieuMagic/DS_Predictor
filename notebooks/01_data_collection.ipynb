{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a37445",
   "metadata": {},
   "source": [
    "# Thu thập dữ liệu\n",
    "\n",
    "## Giới thiệu\n",
    "Dự án xây dựng mô hình dự đoán giá ô tô thông qua dữ liệu thực tế lấy từ các website mua bán xe trực tuyến. Notebook này tóm tắt quy trình lấy dữ liệu từ hai trang mua bán lớn của Việt Nam và chuẩn hóa chúng cho việc mô hình hóa.\n",
    "\n",
    "## Mục tiêu\n",
    "- Thu thập các thông số kỹ thuật (features) chính xác từ mỗi website.\n",
    "- Ghi nhận nguồn gốc dữ liệu để so sánh nhanh giữa hai trang.\n",
    "\n",
    "## Phạm vi\n",
    "- Nguồn: Chotot (API) và Bonbanh (web scraping).\n",
    "- Dữ liệu: Tiêu đề, giá, thông số kỹ thuật, vị trí, người bán, số ảnh (nếu có).\n",
    "- Kết quả: CSV trong `datasets/` phục vụ phân tích và huấn luyện mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd32891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd  \n",
    "import re  \n",
    "\n",
    "N = 100  # Số lượng mẫu cần thu thập từ mỗi trang web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4987a22a",
   "metadata": {},
   "source": [
    "## Phương pháp\n",
    "\n",
    "### 1. Thu thập dữ liệu\n",
    "- **Chotot**: Dùng API nội bộ để lấy ID và sinh URL rao bán xe, tránh phải parse toàn bộ trang tìm kiếm.\n",
    "- **Bonbanh**: Đọc trang `bonbanh.com/oto` và scrape danh sách listing, sau đó truy cập từng URL chi tiết.\n",
    "\n",
    "### 2. Trích xuất features\n",
    "#### Chotot\n",
    "- Tiêu đề/giá nằm ở các tag rõ ràng (`<h1>` và `<b class=\"p26z2wb\">`).\n",
    "- Tất cả features được gom trong `div.p1ja3eq0`; cặp `span.bwq0cbs` đầu là label, sau là giá trị.\n",
    "- Đọc vị trí, người bán, mô tả, số ảnh để đánh dấu dữ liệu có đủ thông tin.\n",
    "\n",
    "#### Bonbanh\n",
    "- Tiêu đề/giá nằm trong phần `<h1>` và `<b itemprop=\"price\">`, nhưng HTML thường chứa nhiều newline nên cần làm phẳng chuỗi.\n",
    "- Thông số kỹ thuật ở các `div.row` với `label` thể hiện tên, `span.inp` chứa giá trị.\n",
    "- Lọc chỉ giữ các keys quan trọng (Năm sản xuất, Tình trạng, Hộp số, v.v.) để dễ chuẩn hóa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847250ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chotot_features(url):\n",
    "    \"\"\"\n",
    "    Trích xuất features chi tiết từ trang listing Chotot.\n",
    "    Trả về dict với các label rõ ràng để merge sau này.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        features = {}  \n",
    "        \n",
    "        # Tiêu đề\n",
    "        title_elem = soup.find('h1')\n",
    "        if title_elem:\n",
    "            features['title'] = title_elem.get_text(strip=True)\n",
    "        \n",
    "        # Giá\n",
    "        price_elem = soup.find('b', class_='p26z2wb')\n",
    "        if price_elem:\n",
    "            features['price'] = price_elem.get_text(strip=True)\n",
    "        \n",
    "        # Features từ div.p1ja3eq0 (label trước, value sau)\n",
    "        feature_divs = soup.find_all('div', class_='p1ja3eq0')\n",
    "        for div in feature_divs:\n",
    "            spans = div.find_all('span', class_='bwq0cbs')\n",
    "            if len(spans) >= 2:\n",
    "                key = spans[0].get_text(strip=True)\n",
    "                value = spans[1].get_text(strip=True)\n",
    "                if key and value:\n",
    "                    features[key] = value\n",
    "        \n",
    "        # Vị trí \n",
    "        location_elem = soup.find('span', class_='bwq0cbs', string=re.compile(r'Quận|Phường|Huyện|Tp|Tỉnh'))\n",
    "        if location_elem:\n",
    "            features['location'] = location_elem.get_text(strip=True)\n",
    "        \n",
    "        # Người bán\n",
    "        seller_link = soup.find('a', href=re.compile(r'/user/'))\n",
    "        if seller_link:\n",
    "            seller_name = seller_link.find('b')\n",
    "            if seller_name:\n",
    "                features['seller'] = seller_name.get_text(strip=True)\n",
    "        \n",
    "        # Mô tả \n",
    "        desc_elem = soup.find('div', class_='des_txt')\n",
    "        if desc_elem:\n",
    "            features['description'] = desc_elem.get_text(strip=True)\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi trích xuất từ {url}: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21a92e",
   "metadata": {},
   "source": [
    "### Giải thích hàm trích xuất Chotot\n",
    "Hàm này giả lập một trình duyệt nhẹ, tải về HTML chi tiết của listing, rồi lần lượt gom các cặp nhãn và giá trị từ `div.p1ja3eq0` (div chứa các cặp nhãn và giá trị) vào một dictionary. Những trường quan trọng như vị trí, người bán, mô tả hay số ảnh cũng được giữ lại để dễ đánh giá độ đầy đủ trước khi đẩy toàn bộ sang CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f556c01",
   "metadata": {},
   "source": [
    "#### Bonbanh\n",
    "- Tiêu đề xuất hiện trong `<h1>`.\n",
    "- Giá, tên hãng, tên xe nằm trong tiêu đề.\n",
    "- Các thông số kỹ thuật được phân thành `div.row` (các dòng), mỗi cặp `<label>` và `<span class=\"inp\">` tương ứng với tên và giá trị của thuộc tính.\n",
    "- Lọc chỉ giữ những thuộc tính cốt lõi như Năm sản xuất, Tình trạng, Hộp số... để bảng dữ liệu không bị loãng với thông tin thừa.\n",
    "- Sau cùng, ghi thêm vị trí và người bán để liên kết ngược tới nguồn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bonbanh_features(url):\n",
    "    \"\"\"\n",
    "    Trích xuất features từ URL Bonbanh.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Tiêu đề\n",
    "        title_elem = soup.find('h1')\n",
    "        if title_elem:\n",
    "            features['title'] = title_elem.get_text(strip=True)\n",
    "    \n",
    "        # Các thông số kỹ thuật\n",
    "        desired_keys = [\n",
    "            'Năm sản xuất',\n",
    "            'Tình trạng',\n",
    "            'Số Km đã đi',\n",
    "            'Xuất xứ',\n",
    "            'Kiểu dáng',\n",
    "            'Hộp số',\n",
    "            'Động cơ',\n",
    "            'Màu ngoại thất',\n",
    "            'Màu nội thất',\n",
    "            'Số chỗ ngồi',\n",
    "            'Số cửa',\n",
    "            'Dẫn động'\n",
    "        ]\n",
    "        rows = soup.find_all('div', class_='row')\n",
    "        for row in rows:\n",
    "            label_elem = row.find('label')\n",
    "            inp_elem = row.find('span', class_='inp')\n",
    "            if label_elem and inp_elem:\n",
    "                key = label_elem.get_text(strip=True).replace(':', '')\n",
    "                value = inp_elem.get_text(strip=True)\n",
    "                if key in desired_keys and value:\n",
    "                    features[key] = value\n",
    "        \n",
    "        # Vị trí + người bán \n",
    "        features['location'] = 'Hà Nội'\n",
    "        seller_elem = soup.find('a', class_='cname')\n",
    "        if seller_elem:\n",
    "            features['seller'] = seller_elem.get_text(strip=True)\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi trích xuất từ {url}: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53684776",
   "metadata": {},
   "source": [
    "### Giải thích hàm trích xuất Bonbanh\n",
    "Chúng ta giữ nguyên tiêu đề như cách người dùng gõ lên trang, chỉ dọn phần head/tail để tránh khoảng trắng dư. Sau khi trang đầy đủ được tải về, danh sách `div.row` cung cấp cặp `label`/`span.inp` nên hàm chỉ nhặt ra những thuộc tính cốt lõi (năm sản xuất, hộp số, màu sắc...) để tránh ghi quá nhiều thông tin thừa. Cuối cùng, location và seller được ghi vào để giữ nguồn gốc dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9acb20",
   "metadata": {},
   "source": [
    "### 3. Triển khai Thu thập URL\n",
    "Trước khi trích xuất feature, chúng ta cần danh sách URL cụ thể. Chotot cung cấp API giúp tránh việc iterate qua từng trang tìm kiếm; Bonbanh không có API công khai nên phải scrape danh sách car-item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d9f24",
   "metadata": {},
   "source": [
    "#### Thu thập URL từ Chotot và Bonbanh\n",
    "- Chotot: gọi API `gateway.chotot.com/v1/public/ad-listing` với tham số limit để lấy top listings.\n",
    "- Bonbanh: tải trang `https://bonbanh.com/oto`, duyệt `li.car-item`, gom tag `<a>` vào danh sách URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_chotot_urls(n=10):\n",
    "    \"\"\"\n",
    "    Thu thập N URL đầu từ trang mua bán ô tô trên chotot.com\n",
    "    bằng cách gọi API gateway.\n",
    "    \"\"\"\n",
    "    base_url = \"https://gateway.chotot.com/v1/public/ad-listing\"\n",
    "    params = {\n",
    "        'w': 1,          # web flag\n",
    "        'limit': n,      # số lượng listings\n",
    "        'st': 's,k',     # sort by score, keyword\n",
    "        'f': 'p',        # filter published\n",
    "        'cg': 2010,      # category: mua bán ô tô\n",
    "        'o': 0,          # offset\n",
    "        'page': 0        # page\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        urls = []\n",
    "        for ad in data.get('ads', []):\n",
    "            list_id = ad.get('list_id')\n",
    "            if list_id:\n",
    "                url = f\"https://xe.chotot.com/mua-ban-oto/{list_id}.htm\"\n",
    "                urls.append(url)\n",
    "        \n",
    "        return urls[:n]\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi khi gọi API: {e}\")\n",
    "        return []\n",
    "\n",
    "# Thu thập N URL đầu\n",
    "chotot_urls = collect_chotot_urls(N)\n",
    "print(f\"Đã thu thập {len(chotot_urls)} URL từ Chotot:\")\n",
    "for url in chotot_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2f05a",
   "metadata": {},
   "source": [
    "### Giải thích hàm collect_chotot_urls\n",
    "Ta gọi API `gateway.chotot.com/v1/public/ad-listing` với các tham số lọc chuẩn để lấy những listing mới nhất và dựng lại URL hoàn chỉnh bằng `list_id`. Cách này tránh phải lướt qua từng trang search và giúp lấy nhanh một tập mẫu có thể mở rộng về sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_bonbanh_urls(n=10):\n",
    "    \"\"\"\n",
    "    Thu thập N URL đầu từ trang mua bán ô tô cũ trên bonbanh.com\n",
    "    bằng cách scrape trang tìm kiếm.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(\"https://bonbanh.com/oto\", headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        urls = []\n",
    "        # Tìm car listings trong li.car-item\n",
    "        listings = soup.find_all('li', class_=lambda x: x and 'car-item' in x)\n",
    "        for li in listings:\n",
    "            a_tag = li.find('a', href=True)\n",
    "            if a_tag:\n",
    "                href = a_tag['href']\n",
    "                if href.startswith('/'):\n",
    "                    full_url = f\"https://bonbanh.com{href}\"\n",
    "                else:\n",
    "                    full_url = f\"https://bonbanh.com/{href}\"\n",
    "                if full_url not in urls:\n",
    "                    urls.append(full_url)\n",
    "        \n",
    "        return urls[:n]\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi khi scrape Bonbanh: {e}\")\n",
    "        return []\n",
    "\n",
    "# Thu thập N URL đầu từ Bonbanh\n",
    "bonbanh_urls = collect_bonbanh_urls(N)\n",
    "print(f\"Đã thu thập {len(bonbanh_urls)} URL từ Bonbanh:\")\n",
    "for url in bonbanh_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1c0ad",
   "metadata": {},
   "source": [
    "### Giải thích hàm collect_bonbanh_urls\n",
    "Vì Bonbanh không cung cấp API, hàm tải trang `https://bonbanh.com/oto`, tìm các `li.car-item` và gom liên kết trong mỗi `<a>` để tạo danh sách URL. Mỗi href được chuyển sang dạng tuyệt đối và các entry trùng được loại bỏ, nên nếu cần ta chỉ việc mở rộng bằng cách duyệt thêm các trang `page=N`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113edc2",
   "metadata": {},
   "source": [
    "### 4. Triển khai Trích xuất và Lưu Dữ liệu\n",
    "Dùng danh sách URL thu thập được để thực thi từng hàm trích xuất riêng biệt, gom kết quả thành DataFrame rồi ghi ra CSV. Chuỗi try/except bảo đảm một listing lỗi không dừng toàn bộ quá trình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad68bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chotot: Đã lưu 10 bản ghi vào datasets/chotot_car_features.csv\n",
      "Bonbanh: Đã lưu 10 bản ghi vào datasets/bonbanh_car_features.csv\n",
      "Bonbanh: Đã lưu 10 bản ghi vào datasets/bonbanh_car_features.csv\n"
     ]
    }
   ],
   "source": [
    "# I. Trích xuất dữ liệu từ Chotot\n",
    "chotot_data = []\n",
    "for url in chotot_urls:\n",
    "    try:\n",
    "        features = extract_chotot_features(url)\n",
    "        chotot_data.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi với URL Chotot {url}: {e}\")\n",
    "\n",
    "df_chotot = pd.DataFrame(chotot_data)\n",
    "df_chotot.to_csv('../datasets/chotot_car_features.csv', index=False)\n",
    "print(f\"Chotot: Đã lưu {len(chotot_data)} bản ghi vào datasets/chotot_car_features.csv\")\n",
    "\n",
    "# II. Trích xuất dữ liệu từ Bonbanh\n",
    "bonbanh_data = []\n",
    "for url in bonbanh_urls:\n",
    "    try:\n",
    "        features = extract_bonbanh_features(url)\n",
    "        bonbanh_data.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi với URL Bonbanh {url}: {e}\")\n",
    "\n",
    "df_bonbanh = pd.DataFrame(bonbanh_data)\n",
    "df_bonbanh.to_csv('../datasets/bonbanh_car_features.csv', index=False)\n",
    "print(f\"Bonbanh: Đã lưu {len(bonbanh_data)} bản ghi vào datasets/bonbanh_car_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77943086",
   "metadata": {},
   "source": [
    "## Kết quả\n",
    "- Dữ liệu từ Chotot được lưu ở `datasets/chotot_car_features.csv`, mỗi bản ghi bao gồm giá, vị trí, người bán, mô tả và số ảnh để đánh giá mức độ đầy đủ trước khi làm sạch.\n",
    "- Dữ liệu từ Bonbanh vào `datasets/bonbanh_car_features.csv`, giữ lại tiêu đề gốc của người bán và những thông số kỹ thuật cốt lõi sau khi lọc để tránh ghi quá nhiều trường không cần thiết."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
